{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETA_Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you run you must complete the following steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Change shipping number header to \"Logical Tracking ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Dont forget to also update the date (Three of them) before the loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date,time\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn=pyodbc.connect(r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "                    r'DBQ=//cpint_data/data/MERCHANDISING/ReBuyers Shared/Daily Updates - Purchasing.mdb;')\n",
    "po_out_qry=\"Select * From [PO Out]\"\n",
    "po_pd=pd.read_sql_query(po_out_qry,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkend_pd = pd.read_excel('weekend_Receipts.xlsx',sheetname='Sheet1',index_col=2)\n",
    "wkend_pd['TRANSACTION_DATE'] = wkend_pd['TRANSACTION_DATE'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "wkend_pd['DT_IMPORTED'] = wkend_pd['DT_IMPORTED'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "wkend_pd['Track_ID'] = wkend_pd['PO_NBR'].map(str)\n",
    "wkend_pd['Track_ID'] = wkend_pd['Track_ID'].astype(str).str[:-2]\n",
    "wkend_pd['Track_ID'] = wkend_pd['Track_ID'] + '-' + wkend_pd.index\n",
    "fri_receipts_pd = wkend_pd.loc[wkend_pd['TRANSACTION_DATE'] == '2018-05-18']\n",
    "wkend_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Past Receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_net = pyodbc.connect(r'DRIVER={NetezzaSQL};'\n",
    "                          r'SERVER=PUREDATA_PRD;'\n",
    "                          r'PORT=5480;'\n",
    "                          r'DATABASE=DNA_PUB_INVENTORY;'\n",
    "                          r'UID=*******;'\n",
    "                          r'PWD=*********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "receipts_qry = ('SELECT WMS_RECEIPTS_ALLORG.SHIPMENT_NUMBER, WMS_RECEIPTS_ALLORG.ORG, '\n",
    "                'WMS_RECEIPTS_ALLORG.TRANSACTION_DATE, WMS_RECEIPTS_ALLORG.VERIFIED, '\n",
    "                'WMS_RECEIPTS_ALLORG.PO_NBR, WMS_RECEIPTS_ALLORG.SKU, '\n",
    "                'WMS_RECEIPTS_ALLORG.RECEIVE_QTY, WMS_RECEIPTS_ALLORG.RECEIVE_CARTON,' \n",
    "                'WMS_RECEIPTS_ALLORG.DT_IMPORTED '\n",
    "                'FROM WMS_RECEIPTS_ALLORG '\n",
    "                \"WHERE ((WMS_RECEIPTS_ALLORG.TRANSACTION_DATE)>'3/1/2018' );\" \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Netezza query\n",
    "wkend_pd=pd.read_sql_query(receipts_qry,conn_net, index_col='SHIPMENT_NUMBER')\n",
    "wkend_pd['TRANSACTION_DATE'] = wkend_pd['TRANSACTION_DATE'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "wkend_pd['DT_IMPORTED'] = wkend_pd['DT_IMPORTED'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "wkend_pd['Track_ID'] = wkend_pd['PO_NBR'].map(str)\n",
    "wkend_pd['Track_ID'] = wkend_pd['Track_ID'].astype(str).str[:-2]\n",
    "wkend_pd['Track_ID'] = wkend_pd['Track_ID'] + '-' + wkend_pd.index\n",
    "fri_receipts_pd = wkend_pd.loc[wkend_pd['TRANSACTION_DATE'] == '2018-05-18']\n",
    "wkend_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just for Mondays Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only use if not Monday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for Mondays Data\n",
    "conn=pyodbc.connect(r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};'\n",
    "                    r'DBQ=//hftdata02/sysdata02/RedCat/Python/ETA_Adjustment/Daily Updates - Purchasing.accdb;')\n",
    "po_out_qry=\"Select * From [PO Out]\"\n",
    "po_pd=pd.read_sql_query(po_out_qry,conn)\n",
    "len(po_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so you dont have to keep pulling the data\n",
    "revert = po_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "po_pd = revert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_hdr_qry = (\"Select [Logical Tracking ID],Vessel,Status,ETD_Date, ETA_Date,POL,POD,[Container Size], \"\n",
    "                \"Cartons,Location,Container,SCAC,IN_DATE, OUT_DATE,Date_Available, Date_Ordered, [Date_Out Gated], \"\n",
    "                \"[Date_1st Arrived], [On Priority], Date_Empty, [Picked up for_Term], Date_Terminated \"\n",
    "                \"From [cont hdr]\")\n",
    "\n",
    "cont_hdr_pd=pd.read_sql_query(cont_hdr_qry,conn, index_col='Logical Tracking ID')\n",
    "\n",
    "cont_dtl_qry = \"Select * From [Cont Dtl]\"\n",
    "\n",
    "cont_dtl_pd=pd.read_sql_query(cont_dtl_qry,conn,index_col='Logical Tracking ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_pd = cont_dtl_pd.join(cont_hdr_pd, lsuffix='_l', rsuffix='_r')\n",
    "cont_pd['Track_ID'] = cont_pd['PO Number']+'-'+cont_pd.index\n",
    "cont_pd.reset_index(inplace=True)\n",
    "cont_pd['Ship Qty'] = cont_pd[cont_pd['Ship Qty'] > 0]['Ship Qty']\n",
    "cont_pd = cont_pd[np.isfinite(cont_pd['Ship Qty'])]\n",
    "cont_pd.reset_index()\n",
    "cont_pd.set_index('Logical Tracking ID',inplace=True)\n",
    "cont_pd['ID'] = cont_pd['Item'].map(str)+'-'+cont_pd['PO Number'].map(str)\n",
    "cont_pd['Ship To Location']='DILLON'\n",
    "cont_pd.loc[cont_pd['Org']=='MOR','Ship To Location']='MORENO VALLEY'\n",
    "cont_pd.loc[cont_pd['Org']=='CAM','Ship To Location']='CAMARILLO'\n",
    "#Filters out all of the lines that were received since the file was last updated. \n",
    "cont_pd = cont_pd[~(cont_pd['Track_ID'].isin(wkend_pd['Track_ID']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_filter_pd=cont_pd[['Item','PO Number','Ship Qty']]\n",
    "po_filter_pd['ID'] = po_filter_pd['Item'].map(str)+'-'+po_filter_pd['PO Number'].map(str)\n",
    "po_filter_pd.reset_index(inplace=True)\n",
    "cont_grouped = po_filter_pd.groupby('ID').sum()\n",
    "cont_grouped = cont_grouped.rename(columns={'Item':'SKU','Ship Qty':'ship_qty'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_pd['ID'] = po_pd['SKU'].map(str)+'-'+po_pd['Legacy PO NUM'].map(str)\n",
    "po_pd.set_index('ID',inplace=True)\n",
    "po_pd = po_pd.join(cont_grouped, how='left', rsuffix='_r')\n",
    "po_pd['ship_qty'].fillna(0, inplace=True)\n",
    "po_pd['ship_qty'] = po_pd['ship_qty'].map(int)\n",
    "po_pd['Adj_Qty_raw']=po_pd['PO Open Qty']-po_pd['ship_qty']\n",
    "po_pd['Adj_Qty'] = np.where(po_pd[\"Adj_Qty_raw\"] <0,0,po_pd['Adj_Qty_raw'])\n",
    "#po_pd['Adj_Qty'] = po_pd[po_pd['Adj_Qty'] > 0]['Adj_Qty']\n",
    "po_pd = po_pd[np.isfinite(po_pd['Adj_Qty'])]\n",
    "po_pd = po_pd.sort_values('Adj_Qty_raw',ascending=True)\n",
    "len(po_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_pd.reset_index(inplace=True)\n",
    "cont_pd=cont_pd[['Logical Tracking ID','Item','PO Number','Ord Qty', 'Ship To Location','Ship Qty','ETD_Date','Supplier Number','ETA_Date','POD']]\n",
    "cont_pd['FOB-Cost']=0\n",
    "cont_pd['PO Open Qty'] = cont_pd['Ship Qty'].values\n",
    "cont_pd = cont_pd.rename(columns={'Item':'SKU','PO Number':'PO Number', 'Ship To Location':'Ship To Location',\n",
    "                                  'POD':'POD','Ship Qty':'Shipped Qty','ETD_Date':'Approved_Date','Supplier Number':'Vendor No',\n",
    "                                  'ETA_Date':'WE_Date'})\n",
    "cont_pd = cont_pd.sort_values('WE_Date',ascending=True)\n",
    "cont_pd['day_of_week']=cont_pd['WE_Date'].dt.dayofweek\n",
    "cont_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fri={0:4,1:3,2:2,3:1,4:0,5:6,6:5}\n",
    "start_date = datetime(2018,5,18) #previous Friday\n",
    "fri_lst =[]\n",
    "for i, row in cont_pd.iterrows():\n",
    "    fri_date = (cont_pd.get_value(i,'WE_Date',takeable=False)\n",
    "                + timedelta(days=fri[cont_pd.get_value(i,'day_of_week',takeable=False)]))\n",
    "    if fri_date <= start_date:\n",
    "        fri_date=start_date\n",
    "    fri_lst.append(fri_date)\n",
    "se = pd.Series(fri_lst)    \n",
    "cont_pd['Fri_date'] = se.values\n",
    "grouped_df = cont_pd.groupby( [ 'Logical Tracking ID','POD', 'Fri_date'] ).size().to_frame(name = 'count').reset_index()\n",
    "grouped_df = grouped_df.groupby(['POD', 'Fri_date']).size().to_frame(name = 'count').reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_cont_df = pd.DataFrame()\n",
    "for i, row in grouped_df.iterrows():\n",
    "    pod_value=grouped_df.get_value(i,'POD',takeable=False)\n",
    "    fri_date_value=grouped_df.get_value(i,'Fri_date',takeable=False)\n",
    "    qty_value=grouped_df.get_value(i,'count',takeable=False)\n",
    "    if fri_date_value == start_date:\n",
    "        low_limit=fri_date_value-timedelta(days=500)\n",
    "    else:\n",
    "        low_limit=fri_date_value-timedelta(days=6)\n",
    "    sub_pd = cont_hdr_pd[(cont_hdr_pd['POD'] == pod_value) & \n",
    "                         (cont_hdr_pd['ETA_Date'] <= fri_date_value)& \n",
    "                         (cont_hdr_pd['ETA_Date'] >= low_limit)]\n",
    "    sub_pd = sub_pd.sort_values('ETA_Date',ascending=True)\n",
    "    qtysum=0\n",
    "    finaldatelst=[]\n",
    "    if fri_date_value <= start_date:\n",
    "        limit = 1\n",
    "    elif pod_value == 'WILMINGTON':\n",
    "        limit = 0.5\n",
    "    else:\n",
    "        limit = 0.7\n",
    "    \n",
    "    for j, rowj in sub_pd.iterrows():\n",
    "        qtysum=qtysum + 1\n",
    "        percent = float(qtysum/qty_value)\n",
    "        if percent<=limit:\n",
    "            final_date=fri_date_value\n",
    "        else:\n",
    "            final_date=fri_date_value + timedelta(days=7)\n",
    "        finaldatelst.append(final_date)\n",
    "    se_sub = pd.Series(finaldatelst)    \n",
    "    sub_pd['Final_date'] = se_sub.values\n",
    "    final_cont_df = final_cont_df.append(sub_pd)\n",
    "final_cont_df.reset_index(inplace=True)\n",
    "grouped_final_df = final_cont_df.groupby( [ 'Logical Tracking ID','POD', 'Final_date'] ).size().to_frame(name = 'count').reset_index()\n",
    "grouped_final_df = final_cont_df.groupby(['POD', 'Final_date']).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "final_cont_df.to_csv(r'\\\\hftdata02\\sysdata02\\RedCat\\python\\ETA_Adjustment\\cont_hdr_adjusted.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = final_cont_df.groupby( [ 'POD', 'Final_date'] ).size().to_frame(name = 'count').reset_index()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cont_df = final_cont_df.set_index('Logical Tracking ID')\n",
    "cont_pd = cont_dtl_pd.join(final_cont_df, rsuffix='_r')\n",
    "cont_pd['Track_ID'] = cont_pd['PO Number']+'-'+cont_pd.index\n",
    "cont_pd.reset_index(inplace=True)\n",
    "cont_pd['Ship Qty'] = cont_pd[cont_pd['Ship Qty'] > 0]['Ship Qty']\n",
    "cont_pd = cont_pd[np.isfinite(cont_pd['Ship Qty'])]\n",
    "po_pd = po_pd[['SKU', 'PO Number', 'Adj_Qty', 'Ship To Location',       \n",
    "       'Shipped Qty', 'Approved_Date', 'Vendor No', 'FOB-Cost', 'WE_Date']]\n",
    "po_pd['POD']='NOT SHIPPED'\n",
    "po_pd=po_pd.rename(columns={'Adj_Qty':'PO Open Qty'})\n",
    "po_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_pd['Ship To Location']='DILLON'\n",
    "cont_pd.loc[cont_pd['Org']=='MOR','Ship To Location']='MORENO VALLEY'\n",
    "cont_pd.loc[cont_pd['Org']=='CAM','Ship To Location']='CAMARILLO'\n",
    "#cont_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filters out all of the lines that were received since the file was last updated. \n",
    "cont_pd = cont_pd[~(cont_pd['Track_ID'].isin(wkend_pd['Track_ID']))]\n",
    "len(cont_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_pd=cont_pd[['Item','PO Number','Ord Qty', 'Ship To Location','Ship Qty','ETD_Date','Supplier Number','POD','Final_date']]\n",
    "cont_pd = cont_pd.rename(columns={'Item':'SKU','PO Number':'PO Number','Ord Qty':'PO Open Qty', 'Ship To Location':'Ship To Location',\n",
    "                                  'POD':'POD','Ship Qty':'Shipped Qty','ETD_Date':'Approved_Date','Supplier Number':'Vendor No',\n",
    "                                  'Final_date':'ETA_Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_pd['FOB-Cost']=0\n",
    "cont_pd['WE_Date']=cont_pd['ETA_Date'] + timedelta(days=7)\n",
    "cont_pd['PO Open Qty'] = cont_pd['Shipped Qty'].values\n",
    "cont_pd['ID'] = cont_pd['SKU'].map(str)+'-'+cont_pd['PO Number'].map(str)\n",
    "cont_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_pd.to_csv(r'\\\\hftdata02\\sysdata02\\RedCat\\python\\ETA_Adjustment\\cont_pd_adjusted.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped_df = cont_pd.groupby( [ 'POD', 'ETA_Date'] ).size().to_frame(name = 'count').reset_index()\n",
    "#grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inbound_pd = po_pd.append(cont_pd)\n",
    "#inbound_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct for partial Receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here is where you will compare the raw PO Out with the new inbound_pd groupbys. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_check_pd = po_pd\n",
    "po_check_pd.reset_index(inplace=True)\n",
    "po_check_pd = po_check_pd[['ID','SKU', 'PO Number', 'PO Open Qty']]\n",
    "po_check_pd = po_check_pd.groupby(['ID','SKU','PO Number']).sum()\n",
    "po_check_pd['PO Open Qty'] = po_check_pd[po_check_pd['PO Open Qty'] > 0]['PO Open Qty']\n",
    "po_check_pd = po_check_pd[np.isfinite(po_check_pd['PO Open Qty'])]\n",
    "po_check_pd.reset_index(inplace=True)\n",
    "po_check_pd.set_index('ID', inplace=True)\n",
    "\n",
    "for i, row in po_check_pd.iterrows():\n",
    "    open_value=po_check_pd.get_value(i,'PO Open Qty',takeable=False)\n",
    "    sku_value=po_check_pd.get_value(i,'SKU',takeable=False)\n",
    "    num_value=po_check_pd.get_value(i,'PO Number',takeable=False)\n",
    "po_check_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_po_out_value=po_check_pd.get_value(i,'PO Open Qty',takeable=False)\n",
    "open_po_out_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_check = inbound_pd[(inbound_pd['PO Number']==num_value) & (inbound_pd['SKU']==sku_value)]\n",
    "#inbound_check = inbound_pd['SKU']==sku_value\n",
    "inbound_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opens = []\n",
    "open_qty = 0\n",
    "total_open = 0\n",
    "for ib, row in inbound_check.iterrows():\n",
    "    open_py_value = inbound_check.get_value(i,'PO Open Qty',takeable=False)\n",
    "    opens.append(open_qty)\n",
    "    total_open = total_open + open_qty\n",
    "if open_py_value/open_po_out_value == 1:\n",
    "    print('all good in the hood')\n",
    "else:\n",
    "    print('no go joe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output preperations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "po_lst = ['PO_01','PO_02','PO_03','PO_04','PO_05','PO_06','PO_07','PO_08','PO_09',\n",
    "          'PO_10','PO_11','PO_12','PO_13','PO_14','PO_15','PO_16','PO_17','PO_18','PO_19',\n",
    "          'PO_20','PO_21','PO_22','PO_23','PO_24','PO_25','PO_26','PO_27','PO_28','PO_29',\n",
    "          'PO_30','PO_31','PO_32','PO_33','PO_34','PO_35','PO_36','PO_37','PO_38','PO_39',\n",
    "          'PO_40','PO_41','PO_42','PO_43','PO_44','PO_45','PO_46','PO_47','PO_48','PO_49',\n",
    "          'PO_50','PO_51','PO_52']\n",
    "\n",
    "po_no_lst = ['PO_NO_01','PO_NO_02','PO_NO_03','PO_NO_04','PO_NO_05','PO_NO_06','PO_NO_07','PO_NO_08','PO_NO_09',\n",
    "             'PO_NO_10','PO_NO_11','PO_NO_12','PO_NO_13','PO_NO_14','PO_NO_15','PO_NO_16','PO_NO_17','PO_NO_18','PO_NO_19',\n",
    "             'PO_NO_20','PO_NO_21','PO_NO_22','PO_NO_23','PO_NO_24','PO_NO_25','PO_NO_26','PO_NO_27','PO_NO_28','PO_NO_29',\n",
    "             'PO_NO_30','PO_NO_31','PO_NO_32','PO_NO_33','PO_NO_34','PO_NO_35','PO_NO_36','PO_NO_37','PO_NO_38','PO_NO_39',\n",
    "             'PO_NO_40','PO_NO_41','PO_NO_42','PO_NO_43','PO_NO_44','PO_NO_45','PO_NO_46','PO_NO_47','PO_NO_48','PO_NO_49',\n",
    "             'PO_NO_50','PO_NO_51','PO_NO_52']\n",
    "x = 0\n",
    "for i in po_lst:\n",
    "    x = x+1\n",
    "    if x ==1:\n",
    "        inbound_pd[i] = np.where(inbound_pd['WE_Date']<=start_date + timedelta(days=7*x),inbound_pd['PO Open Qty'],0)\n",
    "    else:\n",
    "        inbound_pd[i] = np.where(inbound_pd['WE_Date']==start_date + timedelta(days=7*x),inbound_pd['PO Open Qty'],0)\n",
    "x = 0\n",
    "for i in po_no_lst:\n",
    "    x = x+1\n",
    "    if x ==1:\n",
    "        inbound_pd[i] = np.where(inbound_pd['WE_Date']<=start_date + timedelta(days=7*x),inbound_pd['PO Number'],0)\n",
    "    else:\n",
    "        inbound_pd[i] = np.where(inbound_pd['WE_Date']==start_date + timedelta(days=7*x),inbound_pd['PO Number'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Inbound_consolidated_data.xlsx', engine='xlsxwriter')\n",
    "inbound_pd.to_excel(writer,'inbound_pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test=pd.DataFrame()\n",
    "test.reset_index()\n",
    "test.set_index(['Sku','Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
